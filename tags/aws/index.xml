<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AWS on nito95 blog</title>
    <link>https://nito95.github.io/tags/aws/</link>
    <description>Recent content in AWS on nito95 blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 11 Jul 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://nito95.github.io/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Amazon Aurora</title>
      <link>https://nito95.github.io/posts/2021-07-11/</link>
      <pubDate>Sun, 11 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://nito95.github.io/posts/2021-07-11/</guid>
      <description>最近お手伝いしているベンチャーでRDS PostgreSQLをAuroraに移行しました。本番環境がスタンバイレプリカがない状態でRDSインスタンス1台で動いており、可用性を高めた方がいいのでどうせならAuroraに移行しちゃいましょう、と提案しエイヤと移行しました。
その話を友人にしたら、「Auroraって何がすごいん?」と質問されました。前職でも当然のようにAuroraを使っており、Auroraは可用性が高くwriteヘビーなサービスにも強くて少しコストが高い、というザックリしたイメージしかなかったので、フワっとした返答しかできませんでした。
ちゃんと調べてみようと思い、論文 Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases を読んで後日改めて友人に説明したので、そのノリでここにもまとめてみます。
耐障害性とQuorum ストレージは1つで稼働させていると、何かの障害でそのストレージが止まってしまうとサービス全体が止まってしまうことになります。それを回避するために同じシステム環境を2つ用意し、1つは稼働し1つは待機させ、障害が発生した際には待機させていたストレージに稼働を切り替えるだけでサービスが再開するようにして可用性を高めます。いわゆるレプリケーションです。
この2つは常に同じデータを保持していなければなりません。なのでデータを書き込む際には両方に対して書き込みをするわけですが、片方のストレージで障害が起きたりネットワークの不通で書き込みに失敗した場合には2つのデータの整合性を保ちたいのでリトライが行われます。
しかしパフォーマンス面からするとリトライ処理は悪なので、1つくらいストレージが不調でレスポンスが返ってこなくても気にせず進めたい。データの整合性は保ちつつパフォーマンスも下げたくないとなると、解決策としては3つストレージを配置することとなります。 書き込みで3つ並列にリクエストが行い、1つ不調だったとしても2つからレスポンスが返ってこれば不整合なく書き込みが成功したとし、読み込みは3つにリクエストを行い2つから同じレスポンスが返ればそれは最新のデータだとします。多数決が行われるわけです。1つ遅いストレージ(straggler)がいても残り2つが正常なら素早い合意が取れるのでパフォーマンスの面でもメリットがあります。
分散システムにおいて処理の整合性をとるために多数決でもって合意を行うことをQuorum（クオラム）モデルと言います。
しかしここで終わりません。3つに分散させて2/3 Quorumで合意する仕組みでは不十分だとしました。
Auroraは6台構成 AWSの各リージョンには必ず3つ以上のAZ(アベイラビリティーゾーン)があります。AZ同士は物理的に距離が離れており、使われている電源系統も違えばソフトウェアのデプロイ周期も違います。 AWSの障害はAZ単位で起こることが多いので、サーバーを2つ作る場合は1つはAZ-aに置いて、もう1つはAZ-bに置けばAZ-aで障害が起きてもサービスは止まらずに済みます。
先ほど書いた2/3 Quorumでデータベースを構築するならば、AZ-aとAZ-bとAZ-cにそれぞれストレージを1つずつ置きます。ここでもしAZ-aで大規模な火災が起きたらどうなるでしょうか。復旧は数日ではできないので、しばらくAZ-bとAZ-cだけで稼働することになります。ここでさらにAZ-bに置いたストレージ1つに一時的な障害が起きてしまうと、稼働できるのがAZ-cだけとなり、読み込みも書き込みも2/3を満たせず合意が取れなくなります。
このAZ+1障害(AZレベルの障害が起き、さらにストレージ1つに障害が起きる)に対応するためにAuroraでは6台構成とし、4/6の書き込みQuorumと3/6の読み込みQuorumとしました。 各AZに2台ずつ置くことでAZ障害が起きても4つのストレージで読み書きでき、さらに1つ不調となっても3つのストレージで読み込みだけはできるようになります。
なぜ書き込みが4/6で読み込みが3/6なのか　 全体の投票数(ストレージ数)を \(V\)とし、読み込みQuorumの投票数を\(V_{r}\) 書き込みQuorumの投票数を\(V_{w}\)とします。
書き込みでは最新のデータを競合を回避して書き込めることが求められるので、過半数である\(V_{w} &amp;gt; V/2\)を満たす必要があります。もし半分だったらどっちが正解かわからなくなります。一方、読み込みは最新の書き込まれたデータを読むことが求められるので \(V_{r} + V_{w} &amp;gt; V\)を満たす必要があります。書き込みでは過半数を超えたら成功するので、このルールにすることで読み込みQuorumの中には少なくとも1つは最新のデータが必ず含まれることになります。
元々 hoge というデータが6つのストレージそれぞれに入っている状態で、 fuga に書き換えるとします。6つのうち4つは書き込みが成功した一方で2つは書き込みが失敗しました。結果的には過半数を超えるので書き込み成功です。すると次に読み込みを行うと4つからは fuga 2つからは hoge が返ってきます。最新データの取得を保証する意味においては3つから fuga が返ってこれば問題ないわけです。3つから hoge 3つから fuga が返ってくることは書き込みが成功している時点であり得ません。
  分散させることで生じるNetwork I/Oの問題と解決策 ストレージを複数に分散させる場合、問題になるのはNetworkです。従来のレプリケーションされたMySQLでは、書き込みのためにredo log、binlog、doublewrite用のデータページ、メタデータ(FRM)を送る必要があるため、6台構成ではとんでもない量のトラフィックとなってしまいます。 そのためAuroraでは、書き込みの際にネットワークを超えて送られるデータはredo logのみとし、ストレージ層にlog applicatorを置き各ストレージが自立的にredo logを再生することで最新状態までデータリカバリーできるようにしています。
Write-Ahead Log(WAL)とRedo Logとは WALは日本語にするとログ先行書き込みで、データベースに対する処理を行う前に全てログに記録する手法をいいます。例えばUPDATEをかけた場合、データをディスクから読み出してメモリ上で値を変えてディスクにフラッシュする必要があります。これが大量のレコードだった場合はデータをある程度の大きさのチャンクに分けてその塊ごとにUPDATEをかけていきます。 もしその途中で電源が落ちた場合、一部だけ書き換わっていて残りは古いままとなる不整合が発生します。それを防ぐために、書き込みをする前にどのページをどう書き換えるか操作情報を全てログに書きます。電源が落ちて再び電源を入れる際にクラッシュリカバリが走り、ログをチェックし、本来行うべき内容と実際に行われた内容を比較して処理を開始時までundoするか、redoして再開させるか判断することができます。ファイルシステムでいうジャーナリングと似てます。</description>
    </item>
    
  </channel>
</rss>
